# ğŸ™ï¸ TEAM-5 Speech Analysis Pipeline

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.95+-green.svg)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/React-19.2+-61DAFB.svg)](https://reactjs.org/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

An advanced AI-powered speech analysis system that provides real-time personality insights and communication feedback using local LLMs, RAG, and multi-agent AI architecture.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [System Requirements](#system-requirements)
- [Quick Start](#quick-start)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [API Documentation](#api-documentation)
- [Configuration](#configuration)
- [Development](#development)
- [Testing & Evaluation](#testing--evaluation)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [License](#license)

## ğŸŒŸ Overview

TEAM-5 is a comprehensive speech analysis pipeline that combines state-of-the-art speech processing, natural language understanding, and multi-agent AI systems to provide detailed personality insights and communication analysis. The system uses local LLMs (via Ollama) and Retrieval-Augmented Generation (RAG) to deliver personalized, actionable feedback.

### Key Capabilities

- **Real-time Speech Analysis**: Process audio through advanced speech-to-text and acoustic feature extraction
- **Multi-Agent AI System**: Specialized agents for communication, confidence, and personality analysis
- **RAG-Enhanced Reports**: Knowledge-augmented insights using vector database retrieval
- **Quality Assurance**: Built-in evaluation framework using LangChain evaluators
- **Full-Stack Solution**: FastAPI backend + React frontend for seamless user experience

## âœ¨ Features

### Backend Features
- ğŸ¤ **Audio Recording & Processing**: Multi-format audio support with noise reduction
- ğŸ“ **Speech-to-Text**: High-accuracy transcription using Faster-Whisper
- ğŸ“Š **Acoustic Analysis**: Comprehensive feature extraction (pitch, energy, pauses, speech rate)
- ğŸ§  **Multi-Agent AI**: Specialized agents for different analysis aspects
- ğŸ” **RAG System**: ChromaDB-powered knowledge retrieval
- ğŸ›¡ï¸ **Guardrails AI**: Input/output validation and safety checks
- ğŸ“ˆ **Evaluation Framework**: Quality assessment using LangChain evaluators
- ğŸš€ **REST API**: FastAPI-powered endpoints for frontend integration

### Frontend Features
- âš¡ **React + TypeScript**: Modern, type-safe UI development
- ğŸ¨ **Responsive Design**: Works on desktop and mobile devices
- ğŸ“¤ **File Upload**: Support for various audio formats
- ğŸ“Š **Results Visualization**: Interactive display of analysis results
- â±ï¸ **Real-time Feedback**: Instant processing status updates

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend                             â”‚
â”‚                    (React + TypeScript)                      â”‚
â”‚                 Vite Dev Server / Build                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP/REST API
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Backend API                             â”‚
â”‚                     (FastAPI + Uvicorn)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Speech Processing Pipeline                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Audio   â”‚â†’ â”‚  Speech   â”‚â†’ â”‚  Feature â”‚â†’ â”‚   Multi-   â”‚ â”‚
â”‚  â”‚ Recordingâ”‚  â”‚  to Text  â”‚  â”‚Extractionâ”‚  â”‚Agent Systemâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                      â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚            RAG System (ChromaDB + Ollama)              â”‚ â”‚
â”‚  â”‚  - Communication Knowledge    - Confidence Psychology  â”‚ â”‚
â”‚  â”‚  - Personality Traits         - Improvement Tips       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           Evaluation & Guardrails                      â”‚ â”‚
â”‚  â”‚  - LangChain Evaluators  - Input/Output Validation    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚    Ollama    â”‚
                  â”‚ Local LLM    â”‚
                  â”‚  (mistral)   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Breakdown

1. **Speech Processing**: Audio recording, preprocessing, and transcription
2. **Feature Extraction**: Acoustic analysis (openSMILE, PyAnnote)
3. **Multi-Agent System**: 
   - Communication Agent: Analyzes clarity, fluency, structure
   - Confidence Agent: Evaluates vocal confidence and emotional tone
   - Personality Agent: Maps communication patterns to personality traits
4. **RAG System**: Retrieves relevant expert knowledge for enhanced insights
5. **Report Generation**: LLM-powered personalized feedback reports
6. **Evaluation Framework**: Quality assessment and validation

## ğŸ’» System Requirements

### Minimum Requirements
- **OS**: Linux, macOS, or Windows 10+
- **Python**: 3.8 or higher
- **RAM**: 8GB (16GB recommended)
- **Storage**: ~5GB for models and dependencies
- **Node.js**: 18.x or higher (for frontend)
- **Microphone**: Required for audio recording

### Recommended Requirements
- **RAM**: 16GB or more
- **GPU**: CUDA-compatible GPU (optional, for faster inference)
- **Storage**: SSD with 10GB+ free space

## ğŸš€ Quick Start

### Option 1: Full Stack Development

```bash
# Clone the repository
git clone https://github.com/GSMPRANEETH/TEAM-5.git
cd TEAM-5

# Backend setup
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Install and start Ollama
ollama pull mistral

# Start backend API
uvicorn api:app --reload --port 8000

# In a new terminal - Frontend setup
cd ../frontend
npm install
npm run dev
```

### Option 2: Backend Only

```bash
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python main.py  # Run standalone pipeline
```

## ğŸ“¦ Installation

### 1. Clone Repository

```bash
git clone https://github.com/GSMPRANEETH/TEAM-5.git
cd TEAM-5
```

### 2. Backend Setup

#### Create Virtual Environment

```bash
cd backend
python -m venv venv

# Activate virtual environment
# Linux/macOS:
source venv/bin/activate
# Windows:
venv\Scripts\activate
```

#### Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Install Ollama (Required for LLM)

Ollama provides local LLM inference.

**Linux/macOS:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Windows:**
1. Download from [ollama.ai/download](https://ollama.ai/download)
2. Run the installer
3. Add Ollama to PATH:
   - Open "Edit environment variables for your account"
   - Add `C:\Users\%USERNAME%\AppData\Local\Programs\Ollama` to PATH
   - Restart terminal

**Verify Installation:**
```bash
ollama --version
```

#### Pull LLM Model

```bash
ollama pull mistral
```

### 4. Frontend Setup (Optional)

```bash
cd ../frontend
npm install
```

### 5. Configuration

Edit backend configuration files as needed:

- `backend/llm1/llm_config.py` - LLM settings (model, temperature, max tokens)
- `backend/rag/config.py` - RAG system configuration
- `backend/evals/eval_config.py` - Evaluation criteria

## ğŸ¯ Usage

### Running the Full Stack

#### Start Backend API

```bash
cd backend
source venv/bin/activate
uvicorn api:app --reload --port 8000
```

API will be available at: `http://localhost:8000`
API docs: `http://localhost:8000/docs`

#### Start Frontend

```bash
cd frontend
npm run dev
```

Frontend will be available at: `http://localhost:5173`

### Running Backend Standalone

```bash
cd backend
python main.py
```

This will:
1. Record 45 seconds of audio
2. Process and analyze speech
3. Generate comprehensive report
4. Display results in terminal

### Using the API

```python
import requests

# Upload audio file
with open("audio.wav", "rb") as f:
    response = requests.post(
        "http://localhost:8000/analyze",
        files={"file": f}
    )

result = response.json()
print(result)
```

### Running Tests

```bash
cd backend

# Test LLM connection
python test_llm_step5.py

# Test RAG system
python test_rag.py

# Run evaluations
python -m evals.test_evals
```

## ğŸ“ Project Structure

```
TEAM-5/
â”œâ”€â”€ backend/                      # Python backend
â”‚   â”œâ”€â”€ api.py                   # FastAPI application
â”‚   â”œâ”€â”€ main.py                  # Standalone pipeline
â”‚   â”œâ”€â”€ link.py                  # Pipeline orchestration
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ README.md                # Backend documentation
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                  # Multi-agent system
â”‚   â”‚   â”œâ”€â”€ communication_agent.py
â”‚   â”‚   â”œâ”€â”€ confidence_agent.py
â”‚   â”‚   â””â”€â”€ personality_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                     # LLM wrapper (agents)
â”‚   â”‚   â””â”€â”€ local_llm.py
â”‚   â”‚
â”‚   â”œâ”€â”€ llm1/                    # LLM config & reporting
â”‚   â”‚   â”œâ”€â”€ llm_config.py
â”‚   â”‚   â”œâ”€â”€ local_llm.py
â”‚   â”‚   â”œâ”€â”€ prompt_templates.py
â”‚   â”‚   â””â”€â”€ report_generator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                     # RAG system
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â”œâ”€â”€ knowledge_base.py
â”‚   â”‚   â”œâ”€â”€ rag_pipeline.py
â”‚   â”‚   â””â”€â”€ documents/
â”‚   â”‚
â”‚   â”œâ”€â”€ evals/                   # Evaluation framework
â”‚   â”‚   â”œâ”€â”€ eval_config.py
â”‚   â”‚   â”œâ”€â”€ eval_runner.py
â”‚   â”‚   â”œâ”€â”€ eval_refinement.py
â”‚   â”‚   â””â”€â”€ test_evals.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                   # Utilities
â”‚   â”‚   â”œâ”€â”€ parser.py
â”‚   â”‚   â””â”€â”€ feature_scoring.py
â”‚   â”‚
â”‚   â”œâ”€â”€ speech_to_text.py        # Whisper transcription
â”‚   â”œâ”€â”€ speech_features.py       # Acoustic analysis
â”‚   â”œâ”€â”€ record_audio.py          # Audio recording
â”‚   â”œâ”€â”€ preprocess_audio.py      # Audio preprocessing
â”‚   â”œâ”€â”€ guardrails_config.py     # Safety & validation
â”‚   â””â”€â”€ agent.py                 # Agent orchestrator
â”‚
â”œâ”€â”€ frontend/                     # React frontend
â”‚   â”œâ”€â”€ src/                     # Source code
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”œâ”€â”€ public/                  # Static assets
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ README.md                     # This file
```

## ğŸ“š API Documentation

### Endpoints

#### `POST /analyze`
Analyze uploaded audio file.

**Request:**
```http
POST /analyze HTTP/1.1
Content-Type: multipart/form-data

file: <audio_file>
```

**Response:**
```json
{
  "transcript": "...",
  "audio_features": { ... },
  "communication_analysis": { ... },
  "confidence_emotion_analysis": { ... },
  "personality_analysis": { ... },
  "final_report": "..."
}
```

### Interactive API Docs

When the backend is running, visit:
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## âš™ï¸ Configuration

### LLM Configuration (`backend/llm1/llm_config.py`)

```python
LLM_MODEL_NAME = "mistral"  # Change model
TEMPERATURE = 0.3            # Creativity (0.0-1.0)
MAX_TOKENS = 512            # Max response length
```

### RAG Configuration (`backend/rag/config.py`)

```python
CHROMA_PERSIST_DIR = "./chroma_db"  # Vector DB storage
TOP_K_RESULTS = 3                    # Documents to retrieve
```

### Recording Configuration (`backend/main.py`)

```python
DURATION = 45        # Recording duration (seconds)
SAMPLE_RATE = 16000  # Required for Whisper
CHANNELS = 1         # Mono audio
```

## ğŸ› ï¸ Development

### Backend Development

```bash
cd backend
source venv/bin/activate

# Run with auto-reload
uvicorn api:app --reload

# Run tests
python -m pytest

# Format code
black .
flake8 .
```

### Frontend Development

```bash
cd frontend

# Development server
npm run dev

# Build for production
npm run build

# Preview production build
npm run preview

# Lint
npm run lint
```

## ğŸ§ª Testing & Evaluation

### Built-in Evaluations

The system includes a comprehensive evaluation framework:

```bash
cd backend
python -m evals.test_evals
```

**Evaluation Criteria:**
- Helpfulness, Relevance, Coherence
- Actionability, Specificity, Accuracy
- Completeness, Constructiveness

### Manual Testing

```bash
# Test LLM connection
python test_llm_step5.py

# Test RAG retrieval
python test_rag.py

# Test full pipeline
python main.py
```

## ğŸ”§ Troubleshooting

### Ollama Connection Issues

**Error:** `Ollama not available`

**Solution:**
1. Ensure Ollama is running: `ollama serve`
2. Check model is pulled: `ollama list`
3. Pull model if needed: `ollama pull mistral`
4. **Windows**: Verify Ollama is in PATH
5. **Linux/macOS**: Check `which ollama`

### Import Errors

**Solution:**
```bash
# Ensure virtual environment is activated
source venv/bin/activate  # or venv\Scripts\activate

# Reinstall dependencies
pip install -r requirements.txt
```

### Memory Issues

**Solution:**
- Use smaller LLM model
- Reduce `MAX_TOKENS` in configuration
- Close other applications
- Upgrade to 16GB+ RAM

### ChromaDB Issues

**Solution:**
```bash
# Clear database
rm -rf backend/chroma_db/

# Restart backend
```

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines

- Follow PEP 8 for Python code
- Use TypeScript for frontend code
- Add tests for new features
- Update documentation

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Faster-Whisper**: OpenAI Whisper implementation
- **Ollama**: Local LLM runtime
- **LangChain**: LLM application framework
- **ChromaDB**: Vector database for AI
- **FastAPI**: Modern Python web framework
- **React**: UI library

## ğŸ“ Support

For issues and questions:
- Open an issue on [GitHub](https://github.com/GSMPRANEETH/TEAM-5/issues)
- Contact: [Project Team]

## ğŸ—ºï¸ Roadmap

- [ ] Support for additional LLM providers
- [ ] Multi-language support
- [ ] Real-time streaming analysis
- [ ] Advanced visualization dashboards
- [ ] Mobile app
- [ ] Docker containerization
- [ ] Cloud deployment guide

---

**Built with â¤ï¸ by TEAM-5**
(chatgpt)[https://chatgpt.com/g/g-p-693cf63b3d608191a200ca21f1c5f7e2-tts/project]
(perplexity)[https://www.perplexity.ai/spaces/tts-1gnsM.HoSV.NHB6HbWS31g#0]
